{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score # 정확도 함수\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grandmaster = pd.read_csv('../Dataset/perMinuteDataset/10min/GRANDMASTER.csv')\n",
    "data = Grandmaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "win_data = data[['Diff_FirstBLOOD', 'Diff_FirstDRAGON',\n",
    "       'Diff_FirstHERALD', 'Diff_Firsttower', 'dragonType', 'WIN_invadeKill', 'WIN_invadeDeath','WIN_controlWARDPlaced', \n",
    "       'WIN_Kill_top', 'WIN_Kill_jgl', 'WIN_Kill_mid', 'WIN_Kill_ad', 'WIN_Kill_sup',\n",
    "       'WIN_Death_top', 'WIN_Death_jgl', 'WIN_Death_mid', 'WIN_Death_ad', 'WIN_Death_sup', \n",
    "       'WIN_Asisst_top', 'WIN_Asisst_jgl', 'WIN_Asisst_mid', 'WIN_Asisst_ad', 'WIN_Asisst_sup',\n",
    "       'WIN_LV_top', 'WIN_LV_jgl', 'WIN_LV_mid', 'WIN_LV_ad', 'WIN_LV_sup',\n",
    "       'WIN_CS_top', 'WIN_CS_jgl', 'WIN_CS_mid', 'WIN_CS_ad', 'WIN_CS_sup',\n",
    "       'WIN_jglCS_top', 'WIN_jglCS_jgl', 'WIN_jglCS_mid', 'WIN_jglCS_ad', 'WIN_jglCS_sup',\n",
    "       'WIN_GOLD_top', 'WIN_GOLD_jgl', 'WIN_GOLD_mid', 'WIN_GOLD_ad', 'WIN_GOLD_sup',\n",
    "       'WIN_WARDkill', 'WIN_Inhibitor','WIN_TOWERkill', 'WIN_WARDplaced']]\n",
    "lose_data = data[['Diff_FirstBLOOD', 'Diff_FirstDRAGON',\n",
    "       'Diff_FirstHERALD', 'Diff_Firsttower', 'dragonType',\n",
    "       'LOSE_invadeDeath', 'LOSE_invadeKill',\n",
    "       'LOSE_controlWARDPlaced',\n",
    "       'LOSE_Kill_top', 'LOSE_Kill_jgl', 'LOSE_Kill_mid', 'LOSE_Kill_ad', 'LOSE_Kill_sup',\n",
    "       'LOSE_Death_top', 'LOSE_Death_jgl',\n",
    "       'LOSE_Death_mid', 'LOSE_Death_ad', 'LOSE_Death_sup',\n",
    "       'LOSE_Asisst_top', 'LOSE_Asisst_jgl', 'LOSE_Asisst_mid',\n",
    "       'LOSE_Asisst_ad', 'LOSE_Asisst_sup',\n",
    "       'LOSE_LV_top', 'LOSE_LV_jgl',\n",
    "       'LOSE_LV_mid', 'LOSE_LV_ad', 'LOSE_LV_sup',\n",
    "       'LOSE_CS_top', 'LOSE_CS_jgl',\n",
    "       'LOSE_CS_mid', 'LOSE_CS_ad', 'LOSE_CS_sup',\n",
    "       'LOSE_jglCS_top', 'LOSE_jglCS_jgl', 'LOSE_jglCS_mid', 'LOSE_jglCS_ad', 'LOSE_jglCS_sup',\n",
    "       'LOSE_GOLD_top', 'LOSE_GOLD_jgl',\n",
    "       'LOSE_GOLD_mid', 'LOSE_GOLD_ad', 'LOSE_GOLD_sup',\n",
    "       'LOSE_WARDkill', 'LOSE_Inhibitor',\n",
    "       'LOSE_TOWERkill', 'LOSE_WARDplaced']]\n",
    "colName = 'WIN'\n",
    "win_data = win_data.rename(columns={f'{colName}_invadeKill': 'invadeKill', f'{colName}_invadeDeath': 'invadeDeath', \n",
    "                                                  f'{colName}_controlWARDPlaced': 'controlWARDPlaced',\n",
    "                                                  f'{colName}_Kill_top': 'Kill_top',f'{colName}_Kill_jgl': 'Kill_jgl',f'{colName}_Kill_mid': 'Kill_mid',f'{colName}_Kill_ad': 'Kill_ad', f'{colName}_Kill_sup': 'Kill_sup',\n",
    "                                                  f'{colName}_Death_top': 'Death_top',f'{colName}_Death_jgl': 'Death_jgl',f'{colName}_Death_mid': 'Death_mid',f'{colName}_Death_ad': 'Death_ad',f'{colName}_Death_sup': 'Death_sup',\n",
    "                                                  f'{colName}_Asisst_top': 'Assist_top',f'{colName}_Asisst_jgl': 'Assist_jgl',f'{colName}_Asisst_mid': 'Assist_mid',f'{colName}_Asisst_ad': 'Assist_ad',f'{colName}_Asisst_sup': 'Assist_sup',\n",
    "                                                  f'{colName}_LV_top': 'LV_top',f'{colName}_LV_jgl': 'LV_jgl',f'{colName}_LV_mid': 'LV_mid',f'{colName}_LV_ad': 'LV_ad',f'{colName}_LV_sup': 'LV_sup',\n",
    "                                                  f'{colName}_CS_top': 'CS_top',f'{colName}_CS_jgl': 'CS_jgl',f'{colName}_CS_mid': 'CS_mid',f'{colName}_CS_ad': 'CS_ad',f'{colName}_CS_sup': 'CS_sup',\n",
    "                                                  f'{colName}_jglCS_top': 'jglCS_top',f'{colName}_jglCS_jgl': 'jglCS_jgl',f'{colName}_jglCS_mid': 'jglCS_mid',f'{colName}_jglCS_ad': 'jglCS_ad',f'{colName}_jglCS_sup': 'jglCS_sup',\n",
    "                                                  f'{colName}_GOLD_top': 'GOLD_top',f'{colName}_GOLD_jgl': 'GOLD_jgl',f'{colName}_GOLD_mid': 'GOLD_mid',f'{colName}_GOLD_ad': 'GOLD_ad',f'{colName}_GOLD_sup': 'GOLD_sup',\n",
    "                                                  f'{colName}_WARDkill': 'WARDkill',f'{colName}_Inhibitor': 'Inhibitor',f'{colName}_TOWERkill': 'TOWERkill',f'{colName}_WARDplaced': 'WARDplaced'})\n",
    "\n",
    "colName = 'LOSE'\n",
    "lose_data = lose_data.rename(columns={f'{colName}_invadeKill': 'invadeKill', f'{colName}_invadeDeath': 'invadeDeath', \n",
    "                                                  f'{colName}_controlWARDPlaced': 'controlWARDPlaced',\n",
    "                                                  f'{colName}_Kill_top': 'Kill_top',f'{colName}_Kill_jgl': 'Kill_jgl',f'{colName}_Kill_mid': 'Kill_mid',f'{colName}_Kill_ad': 'Kill_ad', f'{colName}_Kill_sup': 'Kill_sup',\n",
    "                                                  f'{colName}_Death_top': 'Death_top',f'{colName}_Death_jgl': 'Death_jgl',f'{colName}_Death_mid': 'Death_mid',f'{colName}_Death_ad': 'Death_ad',f'{colName}_Death_sup': 'Death_sup',\n",
    "                                                  f'{colName}_Asisst_top': 'Assist_top',f'{colName}_Asisst_jgl': 'Assist_jgl',f'{colName}_Asisst_mid': 'Assist_mid',f'{colName}_Asisst_ad': 'Assist_ad',f'{colName}_Asisst_sup': 'Assist_sup',\n",
    "                                                  f'{colName}_LV_top': 'LV_top',f'{colName}_LV_jgl': 'LV_jgl',f'{colName}_LV_mid': 'LV_mid',f'{colName}_LV_ad': 'LV_ad',f'{colName}_LV_sup': 'LV_sup',\n",
    "                                                  f'{colName}_CS_top': 'CS_top',f'{colName}_CS_jgl': 'CS_jgl',f'{colName}_CS_mid': 'CS_mid',f'{colName}_CS_ad': 'CS_ad',f'{colName}_CS_sup': 'CS_sup',\n",
    "                                                  f'{colName}_jglCS_top': 'jglCS_top',f'{colName}_jglCS_jgl': 'jglCS_jgl',f'{colName}_jglCS_mid': 'jglCS_mid',f'{colName}_jglCS_ad': 'jglCS_ad',f'{colName}_jglCS_sup': 'jglCS_sup',\n",
    "                                                  f'{colName}_GOLD_top': 'GOLD_top',f'{colName}_GOLD_jgl': 'GOLD_jgl',f'{colName}_GOLD_mid': 'GOLD_mid',f'{colName}_GOLD_ad': 'GOLD_ad',f'{colName}_GOLD_sup': 'GOLD_sup',\n",
    "                                                  f'{colName}_WARDkill': 'WARDkill',f'{colName}_Inhibitor': 'Inhibitor',f'{colName}_TOWERkill': 'TOWERkill',f'{colName}_WARDplaced': 'WARDplaced'})\n",
    "win_data['result'] = 1\n",
    "lose_data['result'] = 0\n",
    "data = pd.concat([win_data, lose_data], axis=0, ignore_index=True)\n",
    "colCnt = data.shape[1] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c76b440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=50, random_state = 10)\n",
    "lgbm = LGBMClassifier(n_estimators=100, max_depth=10, verbosity=0, min_data_in_leaf=30)\n",
    "cat = CatBoostClassifier(iterations=100, depth=4, learning_rate=0.2, random_state=10)\n",
    "et = ExtraTreesClassifier(n_estimators=100, random_state = 10)\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=1, max_depth=10, random_state = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f4caf",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7ad12b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 스케일링 방법과 정확도, confusion matrix를 비교하기 위한 원본\n",
    "def def_original(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('원본 RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('원본 LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('원본 catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('원본 ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('원본 XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         np_X_train = X_train.values\n",
    "#         X_train_data = np_X_train.reshape((X_train.shape[1]*X_train.shape[0]), 1)\n",
    "#         plt.hist(X_train_data, bins=30, color= 'red', alpha = 0.7)\n",
    "#         plt.title('before data scaling')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed578851",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c25c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0, 분산이 1인 정규분포를 갖도록 만들어준다(표준화).\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def def_StandardScaler(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    std = StandardScaler()\n",
    "    # train data는 fit 메서드를 적용시킨 후 transform, test data는 transform\n",
    "    std.fit(X_train)\n",
    "    std_X_train_scaled = std.transform(X_train)\n",
    "    std_X_test_scaled = std.transform(X_test)\n",
    "    \n",
    "    X_train = std_X_train_scaled\n",
    "    X_test = std_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('StandardScaler RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('StandardScaler LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('StandardScaler catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('StandardScaler ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('StandardScaler XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, rf_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         X_train_scaled_ss = std_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(X_train_scaled_ss, bins=30, alpha = 0.7, density = True)\n",
    "#         plt.title('StandardScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e65181",
   "metadata": {},
   "source": [
    "# MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c5f57ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 피처들이 0과 1사이의 데이터값을 갖도록 함. 최솟값 0, 최댓값 1\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def def_MinMaxScaler(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    mms = MinMaxScaler()\n",
    "    mms.fit(X_train)\n",
    "    mms_X_train_scaled = mms.transform(X_train)\n",
    "    mms_X_test_scaled = mms.transform(X_test)\n",
    "\n",
    "    X_train = mms_X_train_scaled\n",
    "    X_test = mms_X_test_scaled\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('MinMaxScaler RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('MinMaxScaler LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('MinMaxScaler catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('MinMaxScaler ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('MinMaxScaler XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "\n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, rf_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         mms_X_train_scaled_reshape = mms_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(mms_X_train_scaled_reshape, bins=30, color='green', alpha = 0.7)\n",
    "#         plt.title('MinMaxScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c99d46",
   "metadata": {},
   "source": [
    "# MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eca0db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 피처들의 절댓값이 0과 1 사이\n",
    "# 데이터가 -1과 1사이의 범위에 존재\n",
    "# 이상치가 존재한다면 스케일링 방법으로 적절하지 않음.\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "def def_MaxAbsScaler(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    mas = MaxAbsScaler()\n",
    "    mas.fit(X_train)\n",
    "    mas_X_train_scaled = mas.transform(X_train)\n",
    "    mas_X_test_scaled = mas.transform(X_test)\n",
    "    \n",
    "    X_train = mas_X_train_scaled\n",
    "    X_test = mas_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('MaxAbsScaler RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('MaxAbsScaler LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('MaxAbsScaler catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('MaxAbsScaler ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('MaxAbsScaler XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, rf_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         mas_X_train_scaled_reshape = mas_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(mas_X_train_scaled_reshape, bins=30, color='yellow', alpha = 0.7)\n",
    "#         plt.title('MaxAbsScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aca5b7",
   "metadata": {},
   "source": [
    "# RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c567e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler는 평균과 분산을 사용했지만, RobustScaler는 중간값(median)과 사분위값(quartile)을 사용\n",
    "# 따라서 이상치의 영향을 최소화할 수 있음.\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "def def_RobustScaler(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    rbs = RobustScaler()\n",
    "    rbs_X_train_scaled = rbs.fit_transform(X_train)\n",
    "    rbs_X_test_scaled = rbs.transform(X_test)\n",
    "\n",
    "    X_train = rbs_X_train_scaled\n",
    "    X_test = rbs_X_test_scaled\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('RobustScaler RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('RobustScaler LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('RobustScaler catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('RobustScaler ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('RobustScaler XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "\n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         rbs_X_train_scaled_reshape = rbs_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(rbs_X_train_scaled_reshape, bins=30, color='pink', alpha = 0.7)\n",
    "#         plt.title('RobustScaler')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e64e4",
   "metadata": {},
   "source": [
    "# Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ed318525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 4가지 방법은 열을 대상으로 진행, Normalizer는 각 행(row)마다 정규화\n",
    "# 한 행의 모든 피처들 사이의 유클리드 거리가 1이 되도록 데이터값을 만들어준다.\n",
    "from sklearn.preprocessing import Normalizer\n",
    "def def_Normalizer(data, showGraph):\n",
    "    X = data.iloc[:, :colCnt]\n",
    "    y = data.iloc[:, colCnt:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할|\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "    norm = Normalizer()\n",
    "    norm_X_train_scaled = norm.fit_transform(X_train)\n",
    "    norm_X_test_scaled = norm.transform(X_test)\n",
    "    \n",
    "    X_train = norm_X_train_scaled\n",
    "    X_test = norm_X_test_scaled\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pre = rf.predict(X_test)\n",
    "    print('Normalizer RandomForest 정확도 :', round(accuracy_score(y_test, rf_pre)*100, 2))\n",
    "    rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, rf_pre).ravel()\n",
    "    print(f'TN:{rf_tn} FP:{rf_fp} FN:{rf_fn} TP:{rf_tp}')\n",
    "    \n",
    "    lgbm.fit(X_train, y_train)\n",
    "    dtc_pre = lgbm.predict(X_test)\n",
    "    print('Normalizer LGBM 정확도 :', round(accuracy_score(y_test, dtc_pre)*100, 2))\n",
    "    dtc_tn, dtc_fp, dtc_fn, dtc_tp = confusion_matrix(y_test, dtc_pre).ravel()\n",
    "    print(f'TN:{dtc_tn} FP:{dtc_fp} FN:{dtc_fn} TP:{dtc_tp}')\n",
    "    \n",
    "    cat.fit(X_train, y_train)\n",
    "    lr_pre = cat.predict(X_test)\n",
    "    print('Normalizer catBoost 정확도 :', round(accuracy_score(y_test, lr_pre)*100, 2))\n",
    "    lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(y_test, lr_pre).ravel()\n",
    "    print(f'TN:{lr_tn} FP:{lr_fp} FN:{lr_fn} TP:{lr_tp}')\n",
    "\n",
    "    et.fit(X_train, y_train)\n",
    "    et_pre = et.predict(X_test)\n",
    "    print('Normalizer ExtraTree 정확도 :', round(accuracy_score(y_test, et_pre)*100, 2))\n",
    "    et_tn, et_fp, et_fn, et_tp = confusion_matrix(y_test, et_pre).ravel()\n",
    "    print(f'TN:{et_tn} FP:{et_fp} FN:{et_fn} TP:{et_tp}')\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pre = xgb.predict(X_test)\n",
    "    print('Normalizer XGboost 정확도 :', round(accuracy_score(y_test, xgb_pre)*100, 2))\n",
    "    xgb_tn, xgb_fp, xgb_fn, xgb_tp = confusion_matrix(y_test, xgb_pre).ravel()\n",
    "    print(f'TN:{xgb_tn} FP:{xgb_fp} FN:{xgb_fn} TP:{xgb_tp}')\n",
    "    \n",
    "    if showGraph == True:\n",
    "        cm = confusion_matrix(y_test, xgb_pre)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "#         norm_X_train_scaled_reshape = norm_X_train_scaled.reshape((X_train.shape[1]*X_train.shape[0]),1)\n",
    "#         plt.hist(norm_X_train_scaled_reshape, bins=30, color='orange', alpha = 0.7)\n",
    "#         plt.title('Normalizer')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c0ef1efe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 RandomForest 정확도 : 73.63\n",
      "TN:915 FP:320 FN:341 TP:931\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "원본 LGBM 정확도 : 80.26\n",
      "TN:1002 FP:233 FN:262 TP:1010\n",
      "0:\tlearn: 0.6007799\ttotal: 8.53ms\tremaining: 845ms\n",
      "1:\tlearn: 0.5851036\ttotal: 18.1ms\tremaining: 884ms\n",
      "2:\tlearn: 0.5733942\ttotal: 24.4ms\tremaining: 789ms\n",
      "3:\tlearn: 0.5635960\ttotal: 36.2ms\tremaining: 869ms\n",
      "4:\tlearn: 0.5479511\ttotal: 42.9ms\tremaining: 814ms\n",
      "5:\tlearn: 0.5397446\ttotal: 51.8ms\tremaining: 812ms\n",
      "6:\tlearn: 0.5295712\ttotal: 60.4ms\tremaining: 803ms\n",
      "7:\tlearn: 0.5221498\ttotal: 68ms\tremaining: 782ms\n",
      "8:\tlearn: 0.5178662\ttotal: 76.4ms\tremaining: 772ms\n",
      "9:\tlearn: 0.5131702\ttotal: 84.4ms\tremaining: 760ms\n",
      "10:\tlearn: 0.5045039\ttotal: 91.5ms\tremaining: 740ms\n",
      "11:\tlearn: 0.4970294\ttotal: 99.1ms\tremaining: 727ms\n",
      "12:\tlearn: 0.4943825\ttotal: 106ms\tremaining: 710ms\n",
      "13:\tlearn: 0.4881137\ttotal: 114ms\tremaining: 703ms\n",
      "14:\tlearn: 0.4852630\ttotal: 122ms\tremaining: 692ms\n",
      "15:\tlearn: 0.4828895\ttotal: 130ms\tremaining: 683ms\n",
      "16:\tlearn: 0.4771998\ttotal: 138ms\tremaining: 672ms\n",
      "17:\tlearn: 0.4731715\ttotal: 145ms\tremaining: 661ms\n",
      "18:\tlearn: 0.4688880\ttotal: 152ms\tremaining: 650ms\n",
      "19:\tlearn: 0.4657759\ttotal: 160ms\tremaining: 639ms\n",
      "20:\tlearn: 0.4620842\ttotal: 168ms\tremaining: 631ms\n",
      "21:\tlearn: 0.4610134\ttotal: 176ms\tremaining: 626ms\n",
      "22:\tlearn: 0.4594411\ttotal: 184ms\tremaining: 617ms\n",
      "23:\tlearn: 0.4398432\ttotal: 192ms\tremaining: 609ms\n",
      "24:\tlearn: 0.4362160\ttotal: 199ms\tremaining: 598ms\n",
      "25:\tlearn: 0.4343816\ttotal: 207ms\tremaining: 590ms\n",
      "26:\tlearn: 0.4318975\ttotal: 215ms\tremaining: 581ms\n",
      "27:\tlearn: 0.4305098\ttotal: 223ms\tremaining: 573ms\n",
      "28:\tlearn: 0.4289941\ttotal: 231ms\tremaining: 565ms\n",
      "29:\tlearn: 0.4269786\ttotal: 238ms\tremaining: 555ms\n",
      "30:\tlearn: 0.4252465\ttotal: 246ms\tremaining: 547ms\n",
      "31:\tlearn: 0.4233219\ttotal: 253ms\tremaining: 537ms\n",
      "32:\tlearn: 0.4218592\ttotal: 262ms\tremaining: 531ms\n",
      "33:\tlearn: 0.4193285\ttotal: 268ms\tremaining: 521ms\n",
      "34:\tlearn: 0.4176994\ttotal: 278ms\tremaining: 516ms\n",
      "35:\tlearn: 0.4155170\ttotal: 285ms\tremaining: 507ms\n",
      "36:\tlearn: 0.4142555\ttotal: 293ms\tremaining: 498ms\n",
      "37:\tlearn: 0.4133159\ttotal: 300ms\tremaining: 490ms\n",
      "38:\tlearn: 0.4120569\ttotal: 308ms\tremaining: 482ms\n",
      "39:\tlearn: 0.4110522\ttotal: 316ms\tremaining: 474ms\n",
      "40:\tlearn: 0.4103656\ttotal: 324ms\tremaining: 466ms\n",
      "41:\tlearn: 0.4091414\ttotal: 331ms\tremaining: 458ms\n",
      "42:\tlearn: 0.4072162\ttotal: 341ms\tremaining: 452ms\n",
      "43:\tlearn: 0.4061952\ttotal: 349ms\tremaining: 444ms\n",
      "44:\tlearn: 0.4056904\ttotal: 357ms\tremaining: 436ms\n",
      "45:\tlearn: 0.4042336\ttotal: 364ms\tremaining: 427ms\n",
      "46:\tlearn: 0.4037008\ttotal: 372ms\tremaining: 420ms\n",
      "47:\tlearn: 0.4024592\ttotal: 380ms\tremaining: 411ms\n",
      "48:\tlearn: 0.4019747\ttotal: 387ms\tremaining: 403ms\n",
      "49:\tlearn: 0.4014313\ttotal: 395ms\tremaining: 395ms\n",
      "50:\tlearn: 0.3990720\ttotal: 403ms\tremaining: 387ms\n",
      "51:\tlearn: 0.3977589\ttotal: 411ms\tremaining: 379ms\n",
      "52:\tlearn: 0.3969838\ttotal: 418ms\tremaining: 371ms\n",
      "53:\tlearn: 0.3962894\ttotal: 426ms\tremaining: 363ms\n",
      "54:\tlearn: 0.3949562\ttotal: 434ms\tremaining: 355ms\n",
      "55:\tlearn: 0.3935868\ttotal: 442ms\tremaining: 347ms\n",
      "56:\tlearn: 0.3923658\ttotal: 449ms\tremaining: 339ms\n",
      "57:\tlearn: 0.3915883\ttotal: 457ms\tremaining: 331ms\n",
      "58:\tlearn: 0.3901881\ttotal: 465ms\tremaining: 323ms\n",
      "59:\tlearn: 0.3892443\ttotal: 479ms\tremaining: 319ms\n",
      "60:\tlearn: 0.3888190\ttotal: 488ms\tremaining: 312ms\n",
      "61:\tlearn: 0.3881206\ttotal: 495ms\tremaining: 304ms\n",
      "62:\tlearn: 0.3874279\ttotal: 505ms\tremaining: 296ms\n",
      "63:\tlearn: 0.3865117\ttotal: 513ms\tremaining: 288ms\n",
      "64:\tlearn: 0.3854945\ttotal: 522ms\tremaining: 281ms\n",
      "65:\tlearn: 0.3846640\ttotal: 529ms\tremaining: 273ms\n",
      "66:\tlearn: 0.3842642\ttotal: 537ms\tremaining: 264ms\n",
      "67:\tlearn: 0.3841242\ttotal: 544ms\tremaining: 256ms\n",
      "68:\tlearn: 0.3829943\ttotal: 552ms\tremaining: 248ms\n",
      "69:\tlearn: 0.3816322\ttotal: 559ms\tremaining: 239ms\n",
      "70:\tlearn: 0.3808750\ttotal: 566ms\tremaining: 231ms\n",
      "71:\tlearn: 0.3804498\ttotal: 574ms\tremaining: 223ms\n",
      "72:\tlearn: 0.3787385\ttotal: 582ms\tremaining: 215ms\n",
      "73:\tlearn: 0.3780439\ttotal: 590ms\tremaining: 207ms\n",
      "74:\tlearn: 0.3776503\ttotal: 598ms\tremaining: 199ms\n",
      "75:\tlearn: 0.3769018\ttotal: 606ms\tremaining: 191ms\n",
      "76:\tlearn: 0.3763696\ttotal: 614ms\tremaining: 183ms\n",
      "77:\tlearn: 0.3756096\ttotal: 621ms\tremaining: 175ms\n",
      "78:\tlearn: 0.3745283\ttotal: 630ms\tremaining: 167ms\n",
      "79:\tlearn: 0.3740132\ttotal: 639ms\tremaining: 160ms\n",
      "80:\tlearn: 0.3728270\ttotal: 648ms\tremaining: 152ms\n",
      "81:\tlearn: 0.3726603\ttotal: 655ms\tremaining: 144ms\n",
      "82:\tlearn: 0.3720211\ttotal: 664ms\tremaining: 136ms\n",
      "83:\tlearn: 0.3715547\ttotal: 672ms\tremaining: 128ms\n",
      "84:\tlearn: 0.3708484\ttotal: 680ms\tremaining: 120ms\n",
      "85:\tlearn: 0.3704352\ttotal: 689ms\tremaining: 112ms\n",
      "86:\tlearn: 0.3696047\ttotal: 699ms\tremaining: 104ms\n",
      "87:\tlearn: 0.3690602\ttotal: 706ms\tremaining: 96.3ms\n",
      "88:\tlearn: 0.3689820\ttotal: 714ms\tremaining: 88.2ms\n",
      "89:\tlearn: 0.3684004\ttotal: 722ms\tremaining: 80.2ms\n",
      "90:\tlearn: 0.3678810\ttotal: 729ms\tremaining: 72.1ms\n",
      "91:\tlearn: 0.3669814\ttotal: 737ms\tremaining: 64.1ms\n",
      "92:\tlearn: 0.3662157\ttotal: 744ms\tremaining: 56ms\n",
      "93:\tlearn: 0.3656094\ttotal: 753ms\tremaining: 48.1ms\n",
      "94:\tlearn: 0.3651325\ttotal: 762ms\tremaining: 40.1ms\n",
      "95:\tlearn: 0.3646501\ttotal: 769ms\tremaining: 32.1ms\n",
      "96:\tlearn: 0.3637723\ttotal: 777ms\tremaining: 24ms\n",
      "97:\tlearn: 0.3629189\ttotal: 785ms\tremaining: 16ms\n",
      "98:\tlearn: 0.3625980\ttotal: 793ms\tremaining: 8.01ms\n",
      "99:\tlearn: 0.3620111\ttotal: 801ms\tremaining: 0us\n",
      "원본 catBoost 정확도 : 80.45\n",
      "TN:1001 FP:234 FN:256 TP:1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 ExtraTree 정확도 : 77.18\n",
      "TN:980 FP:255 FN:317 TP:955\n",
      "원본 XGboost 정확도 : 77.14\n",
      "TN:971 FP:264 FN:309 TP:963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler RandomForest 정확도 : 73.75\n",
      "TN:915 FP:320 FN:338 TP:934\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "StandardScaler LGBM 정확도 : 79.86\n",
      "TN:991 FP:244 FN:261 TP:1011\n",
      "0:\tlearn: 0.6007799\ttotal: 11.6ms\tremaining: 1.15s\n",
      "1:\tlearn: 0.5851036\ttotal: 21.3ms\tremaining: 1.04s\n",
      "2:\tlearn: 0.5733942\ttotal: 30.8ms\tremaining: 997ms\n",
      "3:\tlearn: 0.5635960\ttotal: 41.1ms\tremaining: 987ms\n",
      "4:\tlearn: 0.5479511\ttotal: 47.8ms\tremaining: 908ms\n",
      "5:\tlearn: 0.5397446\ttotal: 55.7ms\tremaining: 872ms\n",
      "6:\tlearn: 0.5295712\ttotal: 63.5ms\tremaining: 844ms\n",
      "7:\tlearn: 0.5221498\ttotal: 78.2ms\tremaining: 900ms\n",
      "8:\tlearn: 0.5178662\ttotal: 93.1ms\tremaining: 941ms\n",
      "9:\tlearn: 0.5131702\ttotal: 115ms\tremaining: 1.03s\n",
      "10:\tlearn: 0.5045039\ttotal: 139ms\tremaining: 1.12s\n",
      "11:\tlearn: 0.4970294\ttotal: 148ms\tremaining: 1.08s\n",
      "12:\tlearn: 0.4943825\ttotal: 166ms\tremaining: 1.11s\n",
      "13:\tlearn: 0.4881137\ttotal: 176ms\tremaining: 1.08s\n",
      "14:\tlearn: 0.4852630\ttotal: 186ms\tremaining: 1.05s\n",
      "15:\tlearn: 0.4828895\ttotal: 195ms\tremaining: 1.02s\n",
      "16:\tlearn: 0.4771998\ttotal: 205ms\tremaining: 1s\n",
      "17:\tlearn: 0.4731715\ttotal: 230ms\tremaining: 1.05s\n",
      "18:\tlearn: 0.4688880\ttotal: 240ms\tremaining: 1.02s\n",
      "19:\tlearn: 0.4657759\ttotal: 251ms\tremaining: 1s\n",
      "20:\tlearn: 0.4620842\ttotal: 267ms\tremaining: 1s\n",
      "21:\tlearn: 0.4610134\ttotal: 278ms\tremaining: 984ms\n",
      "22:\tlearn: 0.4594411\ttotal: 287ms\tremaining: 962ms\n",
      "23:\tlearn: 0.4398432\ttotal: 297ms\tremaining: 940ms\n",
      "24:\tlearn: 0.4362160\ttotal: 305ms\tremaining: 916ms\n",
      "25:\tlearn: 0.4343816\ttotal: 315ms\tremaining: 896ms\n",
      "26:\tlearn: 0.4318975\ttotal: 324ms\tremaining: 876ms\n",
      "27:\tlearn: 0.4305098\ttotal: 335ms\tremaining: 860ms\n",
      "28:\tlearn: 0.4289941\ttotal: 345ms\tremaining: 844ms\n",
      "29:\tlearn: 0.4269786\ttotal: 354ms\tremaining: 826ms\n",
      "30:\tlearn: 0.4252465\ttotal: 364ms\tremaining: 810ms\n",
      "31:\tlearn: 0.4233219\ttotal: 372ms\tremaining: 791ms\n",
      "32:\tlearn: 0.4218592\ttotal: 382ms\tremaining: 776ms\n",
      "33:\tlearn: 0.4193285\ttotal: 390ms\tremaining: 757ms\n",
      "34:\tlearn: 0.4176994\ttotal: 400ms\tremaining: 743ms\n",
      "35:\tlearn: 0.4155170\ttotal: 409ms\tremaining: 726ms\n",
      "36:\tlearn: 0.4142555\ttotal: 418ms\tremaining: 712ms\n",
      "37:\tlearn: 0.4133159\ttotal: 431ms\tremaining: 702ms\n",
      "38:\tlearn: 0.4120569\ttotal: 441ms\tremaining: 690ms\n",
      "39:\tlearn: 0.4110522\ttotal: 450ms\tremaining: 674ms\n",
      "40:\tlearn: 0.4103656\ttotal: 461ms\tremaining: 663ms\n",
      "41:\tlearn: 0.4091414\ttotal: 470ms\tremaining: 649ms\n",
      "42:\tlearn: 0.4072162\ttotal: 479ms\tremaining: 635ms\n",
      "43:\tlearn: 0.4061952\ttotal: 488ms\tremaining: 621ms\n",
      "44:\tlearn: 0.4056904\ttotal: 498ms\tremaining: 609ms\n",
      "45:\tlearn: 0.4042336\ttotal: 509ms\tremaining: 597ms\n",
      "46:\tlearn: 0.4037008\ttotal: 518ms\tremaining: 585ms\n",
      "47:\tlearn: 0.4024592\ttotal: 530ms\tremaining: 575ms\n",
      "48:\tlearn: 0.4019747\ttotal: 542ms\tremaining: 564ms\n",
      "49:\tlearn: 0.4014313\ttotal: 551ms\tremaining: 551ms\n",
      "50:\tlearn: 0.3990720\ttotal: 563ms\tremaining: 541ms\n",
      "51:\tlearn: 0.3977589\ttotal: 572ms\tremaining: 528ms\n",
      "52:\tlearn: 0.3969838\ttotal: 584ms\tremaining: 518ms\n",
      "53:\tlearn: 0.3962894\ttotal: 601ms\tremaining: 512ms\n",
      "54:\tlearn: 0.3949562\ttotal: 630ms\tremaining: 516ms\n",
      "55:\tlearn: 0.3935868\ttotal: 688ms\tremaining: 540ms\n",
      "56:\tlearn: 0.3923658\ttotal: 696ms\tremaining: 525ms\n",
      "57:\tlearn: 0.3915883\ttotal: 720ms\tremaining: 521ms\n",
      "58:\tlearn: 0.3901881\ttotal: 741ms\tremaining: 515ms\n",
      "59:\tlearn: 0.3892443\ttotal: 758ms\tremaining: 506ms\n",
      "60:\tlearn: 0.3888190\ttotal: 775ms\tremaining: 496ms\n",
      "61:\tlearn: 0.3881206\ttotal: 822ms\tremaining: 504ms\n",
      "62:\tlearn: 0.3874279\ttotal: 842ms\tremaining: 495ms\n",
      "63:\tlearn: 0.3865117\ttotal: 858ms\tremaining: 482ms\n",
      "64:\tlearn: 0.3854945\ttotal: 875ms\tremaining: 471ms\n",
      "65:\tlearn: 0.3846640\ttotal: 889ms\tremaining: 458ms\n",
      "66:\tlearn: 0.3842642\ttotal: 904ms\tremaining: 445ms\n",
      "67:\tlearn: 0.3841242\ttotal: 919ms\tremaining: 432ms\n",
      "68:\tlearn: 0.3829943\ttotal: 928ms\tremaining: 417ms\n",
      "69:\tlearn: 0.3816322\ttotal: 938ms\tremaining: 402ms\n",
      "70:\tlearn: 0.3808750\ttotal: 971ms\tremaining: 397ms\n",
      "71:\tlearn: 0.3804498\ttotal: 986ms\tremaining: 383ms\n",
      "72:\tlearn: 0.3787385\ttotal: 998ms\tremaining: 369ms\n",
      "73:\tlearn: 0.3780439\ttotal: 1.02s\tremaining: 358ms\n",
      "74:\tlearn: 0.3776503\ttotal: 1.06s\tremaining: 355ms\n",
      "75:\tlearn: 0.3769018\ttotal: 1.09s\tremaining: 343ms\n",
      "76:\tlearn: 0.3763696\ttotal: 1.1s\tremaining: 330ms\n",
      "77:\tlearn: 0.3756096\ttotal: 1.12s\tremaining: 316ms\n",
      "78:\tlearn: 0.3745283\ttotal: 1.13s\tremaining: 302ms\n",
      "79:\tlearn: 0.3740132\ttotal: 1.15s\tremaining: 287ms\n",
      "80:\tlearn: 0.3728270\ttotal: 1.17s\tremaining: 275ms\n",
      "81:\tlearn: 0.3726603\ttotal: 1.18s\tremaining: 259ms\n",
      "82:\tlearn: 0.3720211\ttotal: 1.2s\tremaining: 245ms\n",
      "83:\tlearn: 0.3715547\ttotal: 1.21s\tremaining: 230ms\n",
      "84:\tlearn: 0.3708484\ttotal: 1.21s\tremaining: 214ms\n",
      "85:\tlearn: 0.3704352\ttotal: 1.22s\tremaining: 199ms\n",
      "86:\tlearn: 0.3696047\ttotal: 1.23s\tremaining: 184ms\n",
      "87:\tlearn: 0.3690602\ttotal: 1.25s\tremaining: 170ms\n",
      "88:\tlearn: 0.3689820\ttotal: 1.25s\tremaining: 155ms\n",
      "89:\tlearn: 0.3684004\ttotal: 1.27s\tremaining: 141ms\n",
      "90:\tlearn: 0.3678810\ttotal: 1.28s\tremaining: 126ms\n",
      "91:\tlearn: 0.3669814\ttotal: 1.29s\tremaining: 112ms\n",
      "92:\tlearn: 0.3662157\ttotal: 1.3s\tremaining: 97.7ms\n",
      "93:\tlearn: 0.3656094\ttotal: 1.31s\tremaining: 83.7ms\n",
      "94:\tlearn: 0.3651325\ttotal: 1.33s\tremaining: 69.8ms\n",
      "95:\tlearn: 0.3646501\ttotal: 1.34s\tremaining: 55.7ms\n",
      "96:\tlearn: 0.3637723\ttotal: 1.35s\tremaining: 41.7ms\n",
      "97:\tlearn: 0.3629189\ttotal: 1.36s\tremaining: 27.7ms\n",
      "98:\tlearn: 0.3625980\ttotal: 1.37s\tremaining: 13.8ms\n",
      "99:\tlearn: 0.3620111\ttotal: 1.38s\tremaining: 0us\n",
      "StandardScaler catBoost 정확도 : 80.45\n",
      "TN:1001 FP:234 FN:256 TP:1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler ExtraTree 정확도 : 77.18\n",
      "TN:980 FP:255 FN:317 TP:955\n",
      "StandardScaler XGboost 정확도 : 77.14\n",
      "TN:971 FP:264 FN:309 TP:963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler RandomForest 정확도 : 73.59\n",
      "TN:915 FP:320 FN:342 TP:930\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "MinMaxScaler LGBM 정확도 : 79.5\n",
      "TN:992 FP:243 FN:271 TP:1001\n",
      "0:\tlearn: 0.6007799\ttotal: 12.2ms\tremaining: 1.21s\n",
      "1:\tlearn: 0.5851036\ttotal: 20.3ms\tremaining: 996ms\n",
      "2:\tlearn: 0.5733942\ttotal: 32.5ms\tremaining: 1.05s\n",
      "3:\tlearn: 0.5635960\ttotal: 39.8ms\tremaining: 955ms\n",
      "4:\tlearn: 0.5479511\ttotal: 50.7ms\tremaining: 964ms\n",
      "5:\tlearn: 0.5397446\ttotal: 58.1ms\tremaining: 910ms\n",
      "6:\tlearn: 0.5295712\ttotal: 67.7ms\tremaining: 899ms\n",
      "7:\tlearn: 0.5221498\ttotal: 78ms\tremaining: 897ms\n",
      "8:\tlearn: 0.5178662\ttotal: 86.9ms\tremaining: 878ms\n",
      "9:\tlearn: 0.5131702\ttotal: 97.1ms\tremaining: 874ms\n",
      "10:\tlearn: 0.5045039\ttotal: 107ms\tremaining: 866ms\n",
      "11:\tlearn: 0.4970294\ttotal: 116ms\tremaining: 853ms\n",
      "12:\tlearn: 0.4943825\ttotal: 128ms\tremaining: 854ms\n",
      "13:\tlearn: 0.4881137\ttotal: 139ms\tremaining: 852ms\n",
      "14:\tlearn: 0.4852630\ttotal: 149ms\tremaining: 842ms\n",
      "15:\tlearn: 0.4828895\ttotal: 159ms\tremaining: 837ms\n",
      "16:\tlearn: 0.4771998\ttotal: 169ms\tremaining: 824ms\n",
      "17:\tlearn: 0.4731715\ttotal: 180ms\tremaining: 822ms\n",
      "18:\tlearn: 0.4688880\ttotal: 191ms\tremaining: 815ms\n",
      "19:\tlearn: 0.4657759\ttotal: 201ms\tremaining: 805ms\n",
      "20:\tlearn: 0.4620842\ttotal: 215ms\tremaining: 809ms\n",
      "21:\tlearn: 0.4610134\ttotal: 232ms\tremaining: 821ms\n",
      "22:\tlearn: 0.4594411\ttotal: 243ms\tremaining: 814ms\n",
      "23:\tlearn: 0.4398432\ttotal: 254ms\tremaining: 803ms\n",
      "24:\tlearn: 0.4362160\ttotal: 264ms\tremaining: 793ms\n",
      "25:\tlearn: 0.4343816\ttotal: 276ms\tremaining: 784ms\n",
      "26:\tlearn: 0.4318975\ttotal: 285ms\tremaining: 769ms\n",
      "27:\tlearn: 0.4305098\ttotal: 295ms\tremaining: 759ms\n",
      "28:\tlearn: 0.4289941\ttotal: 305ms\tremaining: 746ms\n",
      "29:\tlearn: 0.4269786\ttotal: 317ms\tremaining: 739ms\n",
      "30:\tlearn: 0.4252465\ttotal: 329ms\tremaining: 731ms\n",
      "31:\tlearn: 0.4233219\ttotal: 340ms\tremaining: 722ms\n",
      "32:\tlearn: 0.4218592\ttotal: 349ms\tremaining: 708ms\n",
      "33:\tlearn: 0.4193285\ttotal: 360ms\tremaining: 698ms\n",
      "34:\tlearn: 0.4176994\ttotal: 374ms\tremaining: 694ms\n",
      "35:\tlearn: 0.4155170\ttotal: 385ms\tremaining: 685ms\n",
      "36:\tlearn: 0.4142555\ttotal: 397ms\tremaining: 676ms\n",
      "37:\tlearn: 0.4133159\ttotal: 407ms\tremaining: 664ms\n",
      "38:\tlearn: 0.4120569\ttotal: 415ms\tremaining: 650ms\n",
      "39:\tlearn: 0.4110522\ttotal: 427ms\tremaining: 640ms\n",
      "40:\tlearn: 0.4103656\ttotal: 435ms\tremaining: 626ms\n",
      "41:\tlearn: 0.4091414\ttotal: 446ms\tremaining: 616ms\n",
      "42:\tlearn: 0.4072162\ttotal: 459ms\tremaining: 609ms\n",
      "43:\tlearn: 0.4061952\ttotal: 471ms\tremaining: 600ms\n",
      "44:\tlearn: 0.4056904\ttotal: 480ms\tremaining: 587ms\n",
      "45:\tlearn: 0.4042336\ttotal: 493ms\tremaining: 578ms\n",
      "46:\tlearn: 0.4037008\ttotal: 505ms\tremaining: 570ms\n",
      "47:\tlearn: 0.4024592\ttotal: 514ms\tremaining: 557ms\n",
      "48:\tlearn: 0.4019747\ttotal: 527ms\tremaining: 549ms\n",
      "49:\tlearn: 0.4014313\ttotal: 539ms\tremaining: 539ms\n",
      "50:\tlearn: 0.3990720\ttotal: 549ms\tremaining: 527ms\n",
      "51:\tlearn: 0.3977589\ttotal: 559ms\tremaining: 516ms\n",
      "52:\tlearn: 0.3969838\ttotal: 569ms\tremaining: 504ms\n",
      "53:\tlearn: 0.3962894\ttotal: 578ms\tremaining: 492ms\n",
      "54:\tlearn: 0.3949562\ttotal: 589ms\tremaining: 482ms\n",
      "55:\tlearn: 0.3935868\ttotal: 598ms\tremaining: 470ms\n",
      "56:\tlearn: 0.3923658\ttotal: 608ms\tremaining: 459ms\n",
      "57:\tlearn: 0.3915883\ttotal: 620ms\tremaining: 449ms\n",
      "58:\tlearn: 0.3901881\ttotal: 631ms\tremaining: 438ms\n",
      "59:\tlearn: 0.3892443\ttotal: 643ms\tremaining: 428ms\n",
      "60:\tlearn: 0.3888190\ttotal: 654ms\tremaining: 418ms\n",
      "61:\tlearn: 0.3881206\ttotal: 664ms\tremaining: 407ms\n",
      "62:\tlearn: 0.3874279\ttotal: 676ms\tremaining: 397ms\n",
      "63:\tlearn: 0.3865117\ttotal: 687ms\tremaining: 386ms\n",
      "64:\tlearn: 0.3854945\ttotal: 698ms\tremaining: 376ms\n",
      "65:\tlearn: 0.3846640\ttotal: 707ms\tremaining: 364ms\n",
      "66:\tlearn: 0.3842642\ttotal: 720ms\tremaining: 354ms\n",
      "67:\tlearn: 0.3841242\ttotal: 728ms\tremaining: 343ms\n",
      "68:\tlearn: 0.3829943\ttotal: 739ms\tremaining: 332ms\n",
      "69:\tlearn: 0.3816322\ttotal: 750ms\tremaining: 322ms\n",
      "70:\tlearn: 0.3808750\ttotal: 760ms\tremaining: 310ms\n",
      "71:\tlearn: 0.3804498\ttotal: 773ms\tremaining: 301ms\n",
      "72:\tlearn: 0.3787385\ttotal: 784ms\tremaining: 290ms\n",
      "73:\tlearn: 0.3780439\ttotal: 794ms\tremaining: 279ms\n",
      "74:\tlearn: 0.3776503\ttotal: 805ms\tremaining: 268ms\n",
      "75:\tlearn: 0.3769018\ttotal: 814ms\tremaining: 257ms\n",
      "76:\tlearn: 0.3763696\ttotal: 823ms\tremaining: 246ms\n",
      "77:\tlearn: 0.3756096\ttotal: 833ms\tremaining: 235ms\n",
      "78:\tlearn: 0.3745283\ttotal: 842ms\tremaining: 224ms\n",
      "79:\tlearn: 0.3740132\ttotal: 852ms\tremaining: 213ms\n",
      "80:\tlearn: 0.3728270\ttotal: 861ms\tremaining: 202ms\n",
      "81:\tlearn: 0.3726603\ttotal: 870ms\tremaining: 191ms\n",
      "82:\tlearn: 0.3720211\ttotal: 879ms\tremaining: 180ms\n",
      "83:\tlearn: 0.3715547\ttotal: 888ms\tremaining: 169ms\n",
      "84:\tlearn: 0.3708484\ttotal: 898ms\tremaining: 158ms\n",
      "85:\tlearn: 0.3704352\ttotal: 906ms\tremaining: 147ms\n",
      "86:\tlearn: 0.3696047\ttotal: 915ms\tremaining: 137ms\n",
      "87:\tlearn: 0.3690602\ttotal: 924ms\tremaining: 126ms\n",
      "88:\tlearn: 0.3689820\ttotal: 933ms\tremaining: 115ms\n",
      "89:\tlearn: 0.3684004\ttotal: 942ms\tremaining: 105ms\n",
      "90:\tlearn: 0.3678810\ttotal: 952ms\tremaining: 94.1ms\n",
      "91:\tlearn: 0.3669814\ttotal: 964ms\tremaining: 83.8ms\n",
      "92:\tlearn: 0.3662157\ttotal: 972ms\tremaining: 73.1ms\n",
      "93:\tlearn: 0.3656094\ttotal: 982ms\tremaining: 62.7ms\n",
      "94:\tlearn: 0.3651325\ttotal: 993ms\tremaining: 52.2ms\n",
      "95:\tlearn: 0.3646501\ttotal: 1s\tremaining: 41.7ms\n",
      "96:\tlearn: 0.3637723\ttotal: 1.01s\tremaining: 31.3ms\n",
      "97:\tlearn: 0.3629189\ttotal: 1.02s\tremaining: 20.8ms\n",
      "98:\tlearn: 0.3625980\ttotal: 1.03s\tremaining: 10.4ms\n",
      "99:\tlearn: 0.3620111\ttotal: 1.04s\tremaining: 0us\n",
      "MinMaxScaler catBoost 정확도 : 80.45\n",
      "TN:1001 FP:234 FN:256 TP:1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler ExtraTree 정확도 : 77.18\n",
      "TN:980 FP:255 FN:317 TP:955\n",
      "MinMaxScaler XGboost 정확도 : 77.14\n",
      "TN:971 FP:264 FN:309 TP:963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler RandomForest 정확도 : 73.55\n",
      "TN:915 FP:320 FN:343 TP:929\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "MaxAbsScaler LGBM 정확도 : 80.26\n",
      "TN:1002 FP:233 FN:262 TP:1010\n",
      "0:\tlearn: 0.6007799\ttotal: 21.4ms\tremaining: 2.12s\n",
      "1:\tlearn: 0.5851036\ttotal: 33.5ms\tremaining: 1.64s\n",
      "2:\tlearn: 0.5733942\ttotal: 44.8ms\tremaining: 1.45s\n",
      "3:\tlearn: 0.5635960\ttotal: 54.5ms\tremaining: 1.31s\n",
      "4:\tlearn: 0.5479511\ttotal: 63.8ms\tremaining: 1.21s\n",
      "5:\tlearn: 0.5397446\ttotal: 76.9ms\tremaining: 1.21s\n",
      "6:\tlearn: 0.5295712\ttotal: 87.6ms\tremaining: 1.16s\n",
      "7:\tlearn: 0.5221498\ttotal: 98ms\tremaining: 1.13s\n",
      "8:\tlearn: 0.5178662\ttotal: 112ms\tremaining: 1.13s\n",
      "9:\tlearn: 0.5131702\ttotal: 123ms\tremaining: 1.1s\n",
      "10:\tlearn: 0.5045039\ttotal: 132ms\tremaining: 1.07s\n",
      "11:\tlearn: 0.4970294\ttotal: 145ms\tremaining: 1.07s\n",
      "12:\tlearn: 0.4943825\ttotal: 158ms\tremaining: 1.06s\n",
      "13:\tlearn: 0.4881137\ttotal: 166ms\tremaining: 1.02s\n",
      "14:\tlearn: 0.4852630\ttotal: 177ms\tremaining: 1s\n",
      "15:\tlearn: 0.4828895\ttotal: 190ms\tremaining: 998ms\n",
      "16:\tlearn: 0.4771998\ttotal: 199ms\tremaining: 973ms\n",
      "17:\tlearn: 0.4731715\ttotal: 211ms\tremaining: 963ms\n",
      "18:\tlearn: 0.4688880\ttotal: 222ms\tremaining: 948ms\n",
      "19:\tlearn: 0.4657759\ttotal: 230ms\tremaining: 921ms\n",
      "20:\tlearn: 0.4620842\ttotal: 244ms\tremaining: 917ms\n",
      "21:\tlearn: 0.4610134\ttotal: 255ms\tremaining: 904ms\n",
      "22:\tlearn: 0.4594411\ttotal: 265ms\tremaining: 888ms\n",
      "23:\tlearn: 0.4398432\ttotal: 278ms\tremaining: 879ms\n",
      "24:\tlearn: 0.4362160\ttotal: 305ms\tremaining: 915ms\n",
      "25:\tlearn: 0.4343816\ttotal: 318ms\tremaining: 905ms\n",
      "26:\tlearn: 0.4318975\ttotal: 336ms\tremaining: 909ms\n",
      "27:\tlearn: 0.4305098\ttotal: 357ms\tremaining: 919ms\n",
      "28:\tlearn: 0.4289941\ttotal: 394ms\tremaining: 966ms\n",
      "29:\tlearn: 0.4269786\ttotal: 408ms\tremaining: 953ms\n",
      "30:\tlearn: 0.4252465\ttotal: 424ms\tremaining: 943ms\n",
      "31:\tlearn: 0.4233219\ttotal: 439ms\tremaining: 933ms\n",
      "32:\tlearn: 0.4218592\ttotal: 454ms\tremaining: 921ms\n",
      "33:\tlearn: 0.4193285\ttotal: 464ms\tremaining: 900ms\n",
      "34:\tlearn: 0.4176994\ttotal: 479ms\tremaining: 890ms\n",
      "35:\tlearn: 0.4155170\ttotal: 492ms\tremaining: 875ms\n",
      "36:\tlearn: 0.4142555\ttotal: 508ms\tremaining: 865ms\n",
      "37:\tlearn: 0.4133159\ttotal: 521ms\tremaining: 850ms\n",
      "38:\tlearn: 0.4120569\ttotal: 531ms\tremaining: 831ms\n",
      "39:\tlearn: 0.4110522\ttotal: 548ms\tremaining: 822ms\n",
      "40:\tlearn: 0.4103656\ttotal: 577ms\tremaining: 830ms\n",
      "41:\tlearn: 0.4091414\ttotal: 590ms\tremaining: 815ms\n",
      "42:\tlearn: 0.4072162\ttotal: 602ms\tremaining: 799ms\n",
      "43:\tlearn: 0.4061952\ttotal: 613ms\tremaining: 780ms\n",
      "44:\tlearn: 0.4056904\ttotal: 631ms\tremaining: 771ms\n",
      "45:\tlearn: 0.4042336\ttotal: 644ms\tremaining: 756ms\n",
      "46:\tlearn: 0.4037008\ttotal: 658ms\tremaining: 742ms\n",
      "47:\tlearn: 0.4024592\ttotal: 679ms\tremaining: 736ms\n",
      "48:\tlearn: 0.4019747\ttotal: 689ms\tremaining: 718ms\n",
      "49:\tlearn: 0.4014313\ttotal: 707ms\tremaining: 707ms\n",
      "50:\tlearn: 0.3990720\ttotal: 720ms\tremaining: 692ms\n",
      "51:\tlearn: 0.3977589\ttotal: 736ms\tremaining: 679ms\n",
      "52:\tlearn: 0.3969838\ttotal: 749ms\tremaining: 664ms\n",
      "53:\tlearn: 0.3962894\ttotal: 759ms\tremaining: 647ms\n",
      "54:\tlearn: 0.3949562\ttotal: 773ms\tremaining: 633ms\n",
      "55:\tlearn: 0.3935868\ttotal: 788ms\tremaining: 619ms\n",
      "56:\tlearn: 0.3923658\ttotal: 801ms\tremaining: 604ms\n",
      "57:\tlearn: 0.3915883\ttotal: 814ms\tremaining: 589ms\n",
      "58:\tlearn: 0.3901881\ttotal: 829ms\tremaining: 576ms\n",
      "59:\tlearn: 0.3892443\ttotal: 840ms\tremaining: 560ms\n",
      "60:\tlearn: 0.3888190\ttotal: 853ms\tremaining: 546ms\n",
      "61:\tlearn: 0.3881206\ttotal: 867ms\tremaining: 531ms\n",
      "62:\tlearn: 0.3874279\ttotal: 880ms\tremaining: 517ms\n",
      "63:\tlearn: 0.3865117\ttotal: 889ms\tremaining: 500ms\n",
      "64:\tlearn: 0.3854945\ttotal: 900ms\tremaining: 485ms\n",
      "65:\tlearn: 0.3846640\ttotal: 915ms\tremaining: 472ms\n",
      "66:\tlearn: 0.3842642\ttotal: 929ms\tremaining: 457ms\n",
      "67:\tlearn: 0.3841242\ttotal: 946ms\tremaining: 445ms\n",
      "68:\tlearn: 0.3829943\ttotal: 956ms\tremaining: 430ms\n",
      "69:\tlearn: 0.3816322\ttotal: 969ms\tremaining: 415ms\n",
      "70:\tlearn: 0.3808750\ttotal: 984ms\tremaining: 402ms\n",
      "71:\tlearn: 0.3804498\ttotal: 996ms\tremaining: 387ms\n",
      "72:\tlearn: 0.3787385\ttotal: 1.01s\tremaining: 375ms\n",
      "73:\tlearn: 0.3780439\ttotal: 1.04s\tremaining: 366ms\n",
      "74:\tlearn: 0.3776503\ttotal: 1.06s\tremaining: 353ms\n",
      "75:\tlearn: 0.3769018\ttotal: 1.08s\tremaining: 342ms\n",
      "76:\tlearn: 0.3763696\ttotal: 1.1s\tremaining: 328ms\n",
      "77:\tlearn: 0.3756096\ttotal: 1.11s\tremaining: 315ms\n",
      "78:\tlearn: 0.3745283\ttotal: 1.14s\tremaining: 302ms\n",
      "79:\tlearn: 0.3740132\ttotal: 1.15s\tremaining: 288ms\n",
      "80:\tlearn: 0.3728270\ttotal: 1.17s\tremaining: 274ms\n",
      "81:\tlearn: 0.3726603\ttotal: 1.18s\tremaining: 260ms\n",
      "82:\tlearn: 0.3720211\ttotal: 1.2s\tremaining: 245ms\n",
      "83:\tlearn: 0.3715547\ttotal: 1.21s\tremaining: 230ms\n",
      "84:\tlearn: 0.3708484\ttotal: 1.22s\tremaining: 215ms\n",
      "85:\tlearn: 0.3704352\ttotal: 1.23s\tremaining: 200ms\n",
      "86:\tlearn: 0.3696047\ttotal: 1.24s\tremaining: 186ms\n",
      "87:\tlearn: 0.3690602\ttotal: 1.26s\tremaining: 172ms\n",
      "88:\tlearn: 0.3689820\ttotal: 1.27s\tremaining: 158ms\n",
      "89:\tlearn: 0.3684004\ttotal: 1.31s\tremaining: 146ms\n",
      "90:\tlearn: 0.3678810\ttotal: 1.33s\tremaining: 131ms\n",
      "91:\tlearn: 0.3669814\ttotal: 1.34s\tremaining: 117ms\n",
      "92:\tlearn: 0.3662157\ttotal: 1.38s\tremaining: 104ms\n",
      "93:\tlearn: 0.3656094\ttotal: 1.41s\tremaining: 89.7ms\n",
      "94:\tlearn: 0.3651325\ttotal: 1.43s\tremaining: 75.3ms\n",
      "95:\tlearn: 0.3646501\ttotal: 1.46s\tremaining: 60.8ms\n",
      "96:\tlearn: 0.3637723\ttotal: 1.47s\tremaining: 45.5ms\n",
      "97:\tlearn: 0.3629189\ttotal: 1.49s\tremaining: 30.4ms\n",
      "98:\tlearn: 0.3625980\ttotal: 1.5s\tremaining: 15.2ms\n",
      "99:\tlearn: 0.3620111\ttotal: 1.52s\tremaining: 0us\n",
      "MaxAbsScaler catBoost 정확도 : 80.45\n",
      "TN:1001 FP:234 FN:256 TP:1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler ExtraTree 정확도 : 77.18\n",
      "TN:980 FP:255 FN:317 TP:955\n",
      "MaxAbsScaler XGboost 정확도 : 77.14\n",
      "TN:971 FP:264 FN:309 TP:963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler RandomForest 정확도 : 73.71\n",
      "TN:914 FP:321 FN:338 TP:934\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "RobustScaler LGBM 정확도 : 80.14\n",
      "TN:1011 FP:224 FN:274 TP:998\n",
      "0:\tlearn: 0.6007799\ttotal: 15.4ms\tremaining: 1.52s\n",
      "1:\tlearn: 0.5851036\ttotal: 23.2ms\tremaining: 1.14s\n",
      "2:\tlearn: 0.5733942\ttotal: 33.7ms\tremaining: 1.09s\n",
      "3:\tlearn: 0.5635960\ttotal: 43.3ms\tremaining: 1.04s\n",
      "4:\tlearn: 0.5479511\ttotal: 51.4ms\tremaining: 977ms\n",
      "5:\tlearn: 0.5397446\ttotal: 63ms\tremaining: 986ms\n",
      "6:\tlearn: 0.5295712\ttotal: 72ms\tremaining: 957ms\n",
      "7:\tlearn: 0.5221498\ttotal: 84.4ms\tremaining: 971ms\n",
      "8:\tlearn: 0.5178662\ttotal: 94.2ms\tremaining: 953ms\n",
      "9:\tlearn: 0.5131702\ttotal: 105ms\tremaining: 945ms\n",
      "10:\tlearn: 0.5045039\ttotal: 114ms\tremaining: 926ms\n",
      "11:\tlearn: 0.4970294\ttotal: 123ms\tremaining: 904ms\n",
      "12:\tlearn: 0.4943825\ttotal: 132ms\tremaining: 884ms\n",
      "13:\tlearn: 0.4881137\ttotal: 142ms\tremaining: 875ms\n",
      "14:\tlearn: 0.4852630\ttotal: 151ms\tremaining: 854ms\n",
      "15:\tlearn: 0.4828895\ttotal: 162ms\tremaining: 850ms\n",
      "16:\tlearn: 0.4771998\ttotal: 172ms\tremaining: 838ms\n",
      "17:\tlearn: 0.4731715\ttotal: 181ms\tremaining: 824ms\n",
      "18:\tlearn: 0.4688880\ttotal: 190ms\tremaining: 809ms\n",
      "19:\tlearn: 0.4657759\ttotal: 198ms\tremaining: 794ms\n",
      "20:\tlearn: 0.4620842\ttotal: 208ms\tremaining: 784ms\n",
      "21:\tlearn: 0.4610134\ttotal: 218ms\tremaining: 773ms\n",
      "22:\tlearn: 0.4594411\ttotal: 229ms\tremaining: 766ms\n",
      "23:\tlearn: 0.4398432\ttotal: 238ms\tremaining: 754ms\n",
      "24:\tlearn: 0.4362160\ttotal: 246ms\tremaining: 739ms\n",
      "25:\tlearn: 0.4343816\ttotal: 255ms\tremaining: 726ms\n",
      "26:\tlearn: 0.4318975\ttotal: 264ms\tremaining: 713ms\n",
      "27:\tlearn: 0.4305098\ttotal: 276ms\tremaining: 709ms\n",
      "28:\tlearn: 0.4289941\ttotal: 286ms\tremaining: 701ms\n",
      "29:\tlearn: 0.4269786\ttotal: 296ms\tremaining: 690ms\n",
      "30:\tlearn: 0.4252465\ttotal: 306ms\tremaining: 681ms\n",
      "31:\tlearn: 0.4233219\ttotal: 315ms\tremaining: 669ms\n",
      "32:\tlearn: 0.4218592\ttotal: 325ms\tremaining: 661ms\n",
      "33:\tlearn: 0.4193285\ttotal: 334ms\tremaining: 648ms\n",
      "34:\tlearn: 0.4176994\ttotal: 343ms\tremaining: 638ms\n",
      "35:\tlearn: 0.4155170\ttotal: 352ms\tremaining: 626ms\n",
      "36:\tlearn: 0.4142555\ttotal: 361ms\tremaining: 615ms\n",
      "37:\tlearn: 0.4133159\ttotal: 371ms\tremaining: 606ms\n",
      "38:\tlearn: 0.4120569\ttotal: 382ms\tremaining: 598ms\n",
      "39:\tlearn: 0.4110522\ttotal: 392ms\tremaining: 588ms\n",
      "40:\tlearn: 0.4103656\ttotal: 402ms\tremaining: 578ms\n",
      "41:\tlearn: 0.4091414\ttotal: 411ms\tremaining: 567ms\n",
      "42:\tlearn: 0.4072162\ttotal: 420ms\tremaining: 556ms\n",
      "43:\tlearn: 0.4061952\ttotal: 430ms\tremaining: 548ms\n",
      "44:\tlearn: 0.4056904\ttotal: 442ms\tremaining: 541ms\n",
      "45:\tlearn: 0.4042336\ttotal: 451ms\tremaining: 530ms\n",
      "46:\tlearn: 0.4037008\ttotal: 461ms\tremaining: 520ms\n",
      "47:\tlearn: 0.4024592\ttotal: 473ms\tremaining: 512ms\n",
      "48:\tlearn: 0.4019747\ttotal: 483ms\tremaining: 502ms\n",
      "49:\tlearn: 0.4014313\ttotal: 493ms\tremaining: 493ms\n",
      "50:\tlearn: 0.3990720\ttotal: 505ms\tremaining: 485ms\n",
      "51:\tlearn: 0.3977589\ttotal: 515ms\tremaining: 475ms\n",
      "52:\tlearn: 0.3969838\ttotal: 525ms\tremaining: 466ms\n",
      "53:\tlearn: 0.3962894\ttotal: 536ms\tremaining: 457ms\n",
      "54:\tlearn: 0.3949562\ttotal: 545ms\tremaining: 446ms\n",
      "55:\tlearn: 0.3935868\ttotal: 557ms\tremaining: 438ms\n",
      "56:\tlearn: 0.3923658\ttotal: 570ms\tremaining: 430ms\n",
      "57:\tlearn: 0.3915883\ttotal: 581ms\tremaining: 421ms\n",
      "58:\tlearn: 0.3901881\ttotal: 591ms\tremaining: 410ms\n",
      "59:\tlearn: 0.3892443\ttotal: 603ms\tremaining: 402ms\n",
      "60:\tlearn: 0.3888190\ttotal: 614ms\tremaining: 392ms\n",
      "61:\tlearn: 0.3881206\ttotal: 624ms\tremaining: 382ms\n",
      "62:\tlearn: 0.3874279\ttotal: 634ms\tremaining: 372ms\n",
      "63:\tlearn: 0.3865117\ttotal: 644ms\tremaining: 362ms\n",
      "64:\tlearn: 0.3854945\ttotal: 654ms\tremaining: 352ms\n",
      "65:\tlearn: 0.3846640\ttotal: 664ms\tremaining: 342ms\n",
      "66:\tlearn: 0.3842642\ttotal: 673ms\tremaining: 331ms\n",
      "67:\tlearn: 0.3841242\ttotal: 683ms\tremaining: 321ms\n",
      "68:\tlearn: 0.3829943\ttotal: 692ms\tremaining: 311ms\n",
      "69:\tlearn: 0.3816322\ttotal: 702ms\tremaining: 301ms\n",
      "70:\tlearn: 0.3808750\ttotal: 711ms\tremaining: 290ms\n",
      "71:\tlearn: 0.3804498\ttotal: 721ms\tremaining: 280ms\n",
      "72:\tlearn: 0.3787385\ttotal: 732ms\tremaining: 271ms\n",
      "73:\tlearn: 0.3780439\ttotal: 741ms\tremaining: 260ms\n",
      "74:\tlearn: 0.3776503\ttotal: 752ms\tremaining: 251ms\n",
      "75:\tlearn: 0.3769018\ttotal: 764ms\tremaining: 241ms\n",
      "76:\tlearn: 0.3763696\ttotal: 773ms\tremaining: 231ms\n",
      "77:\tlearn: 0.3756096\ttotal: 784ms\tremaining: 221ms\n",
      "78:\tlearn: 0.3745283\ttotal: 795ms\tremaining: 211ms\n",
      "79:\tlearn: 0.3740132\ttotal: 804ms\tremaining: 201ms\n",
      "80:\tlearn: 0.3728270\ttotal: 814ms\tremaining: 191ms\n",
      "81:\tlearn: 0.3726603\ttotal: 826ms\tremaining: 181ms\n",
      "82:\tlearn: 0.3720211\ttotal: 836ms\tremaining: 171ms\n",
      "83:\tlearn: 0.3715547\ttotal: 847ms\tremaining: 161ms\n",
      "84:\tlearn: 0.3708484\ttotal: 860ms\tremaining: 152ms\n",
      "85:\tlearn: 0.3704352\ttotal: 869ms\tremaining: 142ms\n",
      "86:\tlearn: 0.3696047\ttotal: 882ms\tremaining: 132ms\n",
      "87:\tlearn: 0.3690602\ttotal: 892ms\tremaining: 122ms\n",
      "88:\tlearn: 0.3689820\ttotal: 901ms\tremaining: 111ms\n",
      "89:\tlearn: 0.3684004\ttotal: 911ms\tremaining: 101ms\n",
      "90:\tlearn: 0.3678810\ttotal: 920ms\tremaining: 91ms\n",
      "91:\tlearn: 0.3669814\ttotal: 932ms\tremaining: 81.1ms\n",
      "92:\tlearn: 0.3662157\ttotal: 942ms\tremaining: 70.9ms\n",
      "93:\tlearn: 0.3656094\ttotal: 951ms\tremaining: 60.7ms\n",
      "94:\tlearn: 0.3651325\ttotal: 962ms\tremaining: 50.6ms\n",
      "95:\tlearn: 0.3646501\ttotal: 971ms\tremaining: 40.5ms\n",
      "96:\tlearn: 0.3637723\ttotal: 982ms\tremaining: 30.4ms\n",
      "97:\tlearn: 0.3629189\ttotal: 992ms\tremaining: 20.2ms\n",
      "98:\tlearn: 0.3625980\ttotal: 1s\tremaining: 10.1ms\n",
      "99:\tlearn: 0.3620111\ttotal: 1.01s\tremaining: 0us\n",
      "RobustScaler catBoost 정확도 : 80.45\n",
      "TN:1001 FP:234 FN:256 TP:1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler ExtraTree 정확도 : 77.18\n",
      "TN:980 FP:255 FN:317 TP:955\n",
      "RobustScaler XGboost 정확도 : 77.14\n",
      "TN:971 FP:264 FN:309 TP:963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer RandomForest 정확도 : 74.47\n",
      "TN:923 FP:312 FN:328 TP:944\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Normalizer LGBM 정확도 : 80.06\n",
      "TN:985 FP:250 FN:250 TP:1022\n",
      "0:\tlearn: 0.6413843\ttotal: 15.9ms\tremaining: 1.57s\n",
      "1:\tlearn: 0.6171751\ttotal: 27.8ms\tremaining: 1.36s\n",
      "2:\tlearn: 0.5988904\ttotal: 37.2ms\tremaining: 1.2s\n",
      "3:\tlearn: 0.5811178\ttotal: 49.2ms\tremaining: 1.18s\n",
      "4:\tlearn: 0.5718228\ttotal: 60.7ms\tremaining: 1.15s\n",
      "5:\tlearn: 0.5594415\ttotal: 74.5ms\tremaining: 1.17s\n",
      "6:\tlearn: 0.5292342\ttotal: 87ms\tremaining: 1.16s\n",
      "7:\tlearn: 0.5224106\ttotal: 126ms\tremaining: 1.45s\n",
      "8:\tlearn: 0.5170141\ttotal: 136ms\tremaining: 1.38s\n",
      "9:\tlearn: 0.5057197\ttotal: 149ms\tremaining: 1.34s\n",
      "10:\tlearn: 0.4998465\ttotal: 160ms\tremaining: 1.29s\n",
      "11:\tlearn: 0.4954254\ttotal: 174ms\tremaining: 1.28s\n",
      "12:\tlearn: 0.4933293\ttotal: 193ms\tremaining: 1.29s\n",
      "13:\tlearn: 0.4894705\ttotal: 207ms\tremaining: 1.27s\n",
      "14:\tlearn: 0.4871753\ttotal: 219ms\tremaining: 1.24s\n",
      "15:\tlearn: 0.4823332\ttotal: 229ms\tremaining: 1.2s\n",
      "16:\tlearn: 0.4793388\ttotal: 241ms\tremaining: 1.17s\n",
      "17:\tlearn: 0.4755343\ttotal: 253ms\tremaining: 1.15s\n",
      "18:\tlearn: 0.4743033\ttotal: 268ms\tremaining: 1.14s\n",
      "19:\tlearn: 0.4720857\ttotal: 279ms\tremaining: 1.11s\n",
      "20:\tlearn: 0.4706299\ttotal: 290ms\tremaining: 1.09s\n",
      "21:\tlearn: 0.4684711\ttotal: 302ms\tremaining: 1.07s\n",
      "22:\tlearn: 0.4651109\ttotal: 312ms\tremaining: 1.04s\n",
      "23:\tlearn: 0.4644681\ttotal: 323ms\tremaining: 1.02s\n",
      "24:\tlearn: 0.4627083\ttotal: 336ms\tremaining: 1.01s\n",
      "25:\tlearn: 0.4601101\ttotal: 345ms\tremaining: 982ms\n",
      "26:\tlearn: 0.4581694\ttotal: 357ms\tremaining: 965ms\n",
      "27:\tlearn: 0.4565802\ttotal: 368ms\tremaining: 947ms\n",
      "28:\tlearn: 0.4328897\ttotal: 382ms\tremaining: 934ms\n",
      "29:\tlearn: 0.4312325\ttotal: 406ms\tremaining: 947ms\n",
      "30:\tlearn: 0.4213883\ttotal: 426ms\tremaining: 948ms\n",
      "31:\tlearn: 0.4205376\ttotal: 447ms\tremaining: 950ms\n",
      "32:\tlearn: 0.4196931\ttotal: 468ms\tremaining: 949ms\n",
      "33:\tlearn: 0.4187451\ttotal: 481ms\tremaining: 934ms\n",
      "34:\tlearn: 0.4181432\ttotal: 492ms\tremaining: 913ms\n",
      "35:\tlearn: 0.4175929\ttotal: 506ms\tremaining: 900ms\n",
      "36:\tlearn: 0.4157634\ttotal: 521ms\tremaining: 886ms\n",
      "37:\tlearn: 0.4152245\ttotal: 535ms\tremaining: 873ms\n",
      "38:\tlearn: 0.4133421\ttotal: 549ms\tremaining: 858ms\n",
      "39:\tlearn: 0.4125349\ttotal: 570ms\tremaining: 855ms\n",
      "40:\tlearn: 0.4120493\ttotal: 584ms\tremaining: 841ms\n",
      "41:\tlearn: 0.4114705\ttotal: 598ms\tremaining: 825ms\n",
      "42:\tlearn: 0.4104121\ttotal: 618ms\tremaining: 819ms\n",
      "43:\tlearn: 0.4091091\ttotal: 633ms\tremaining: 806ms\n",
      "44:\tlearn: 0.4072457\ttotal: 646ms\tremaining: 790ms\n",
      "45:\tlearn: 0.4060856\ttotal: 663ms\tremaining: 778ms\n",
      "46:\tlearn: 0.4053704\ttotal: 677ms\tremaining: 763ms\n",
      "47:\tlearn: 0.4044282\ttotal: 709ms\tremaining: 768ms\n",
      "48:\tlearn: 0.4032472\ttotal: 727ms\tremaining: 756ms\n",
      "49:\tlearn: 0.4024026\ttotal: 747ms\tremaining: 747ms\n",
      "50:\tlearn: 0.4017447\ttotal: 775ms\tremaining: 744ms\n",
      "51:\tlearn: 0.4006499\ttotal: 794ms\tremaining: 732ms\n",
      "52:\tlearn: 0.3987498\ttotal: 814ms\tremaining: 722ms\n",
      "53:\tlearn: 0.3979473\ttotal: 826ms\tremaining: 704ms\n",
      "54:\tlearn: 0.3965762\ttotal: 835ms\tremaining: 683ms\n",
      "55:\tlearn: 0.3955132\ttotal: 852ms\tremaining: 669ms\n",
      "56:\tlearn: 0.3947629\ttotal: 867ms\tremaining: 654ms\n",
      "57:\tlearn: 0.3937186\ttotal: 881ms\tremaining: 638ms\n",
      "58:\tlearn: 0.3924874\ttotal: 896ms\tremaining: 623ms\n",
      "59:\tlearn: 0.3913128\ttotal: 909ms\tremaining: 606ms\n",
      "60:\tlearn: 0.3904927\ttotal: 924ms\tremaining: 590ms\n",
      "61:\tlearn: 0.3895711\ttotal: 939ms\tremaining: 575ms\n",
      "62:\tlearn: 0.3885654\ttotal: 954ms\tremaining: 561ms\n",
      "63:\tlearn: 0.3878646\ttotal: 968ms\tremaining: 545ms\n",
      "64:\tlearn: 0.3865665\ttotal: 980ms\tremaining: 528ms\n",
      "65:\tlearn: 0.3856742\ttotal: 998ms\tremaining: 514ms\n",
      "66:\tlearn: 0.3776247\ttotal: 1.01s\tremaining: 499ms\n",
      "67:\tlearn: 0.3770507\ttotal: 1.03s\tremaining: 487ms\n",
      "68:\tlearn: 0.3762904\ttotal: 1.05s\tremaining: 474ms\n",
      "69:\tlearn: 0.3755212\ttotal: 1.11s\tremaining: 476ms\n",
      "70:\tlearn: 0.3747688\ttotal: 1.14s\tremaining: 464ms\n",
      "71:\tlearn: 0.3740239\ttotal: 1.15s\tremaining: 449ms\n",
      "72:\tlearn: 0.3727818\ttotal: 1.17s\tremaining: 432ms\n",
      "73:\tlearn: 0.3717394\ttotal: 1.18s\tremaining: 414ms\n",
      "74:\tlearn: 0.3708642\ttotal: 1.19s\tremaining: 398ms\n",
      "75:\tlearn: 0.3700245\ttotal: 1.21s\tremaining: 381ms\n",
      "76:\tlearn: 0.3693237\ttotal: 1.22s\tremaining: 364ms\n",
      "77:\tlearn: 0.3684978\ttotal: 1.24s\tremaining: 350ms\n",
      "78:\tlearn: 0.3679225\ttotal: 1.25s\tremaining: 334ms\n",
      "79:\tlearn: 0.3672244\ttotal: 1.28s\tremaining: 319ms\n",
      "80:\tlearn: 0.3665347\ttotal: 1.29s\tremaining: 303ms\n",
      "81:\tlearn: 0.3661861\ttotal: 1.31s\tremaining: 289ms\n",
      "82:\tlearn: 0.3651627\ttotal: 1.37s\tremaining: 281ms\n",
      "83:\tlearn: 0.3643115\ttotal: 1.4s\tremaining: 267ms\n",
      "84:\tlearn: 0.3638135\ttotal: 1.45s\tremaining: 255ms\n",
      "85:\tlearn: 0.3631752\ttotal: 1.48s\tremaining: 241ms\n",
      "86:\tlearn: 0.3624729\ttotal: 1.5s\tremaining: 224ms\n",
      "87:\tlearn: 0.3618535\ttotal: 1.52s\tremaining: 207ms\n",
      "88:\tlearn: 0.3605356\ttotal: 1.53s\tremaining: 190ms\n",
      "89:\tlearn: 0.3599156\ttotal: 1.55s\tremaining: 172ms\n",
      "90:\tlearn: 0.3591537\ttotal: 1.56s\tremaining: 154ms\n",
      "91:\tlearn: 0.3581869\ttotal: 1.58s\tremaining: 137ms\n",
      "92:\tlearn: 0.3575669\ttotal: 1.59s\tremaining: 120ms\n",
      "93:\tlearn: 0.3568945\ttotal: 1.6s\tremaining: 102ms\n",
      "94:\tlearn: 0.3561405\ttotal: 1.62s\tremaining: 85.1ms\n",
      "95:\tlearn: 0.3554698\ttotal: 1.63s\tremaining: 67.9ms\n",
      "96:\tlearn: 0.3547154\ttotal: 1.64s\tremaining: 50.8ms\n",
      "97:\tlearn: 0.3539906\ttotal: 1.67s\tremaining: 34.1ms\n",
      "98:\tlearn: 0.3532631\ttotal: 1.69s\tremaining: 17.1ms\n",
      "99:\tlearn: 0.3524269\ttotal: 1.71s\tremaining: 0us\n",
      "Normalizer catBoost 정확도 : 80.45\n",
      "TN:991 FP:244 FN:246 TP:1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer ExtraTree 정확도 : 76.71\n",
      "TN:965 FP:270 FN:314 TP:958\n",
      "Normalizer XGboost 정확도 : 77.22\n",
      "TN:965 FP:270 FN:301 TP:971\n"
     ]
    }
   ],
   "source": [
    "# SMOTE, SMOTENC, SMOTEN, ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE \n",
    "# showGraph -> confusion matrix 출력 여부\n",
    "data, showGraph = data, False\n",
    "def_original(data, showGraph)\n",
    "def_StandardScaler(data, showGraph)\n",
    "def_MinMaxScaler(data, showGraph)\n",
    "def_MaxAbsScaler(data, showGraph)\n",
    "def_RobustScaler(data, showGraph)\n",
    "def_Normalizer(data, showGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f44ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
